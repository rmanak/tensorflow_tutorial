{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import urllib.request\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_DIR = '/tmp/tensorflow_tutorials'\n",
    "\n",
    "def download_and_cache(url, fname=None, dest=TEMP_DIR):\n",
    "    if not os.path.exists(dest):\n",
    "        os.makedirs(dest)\n",
    "    if fname is None:\n",
    "        fname = url.split('/')[-1]\n",
    "        print(\"Using fname:\", fname)\n",
    "    fpath = os.path.join(dest, fname)\n",
    "    if not os.path.exists(fpath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            percentage = float(count * block_size) / float(total_size) * 100.0\n",
    "            sys.stdout.write('\\r>> Downloading {} {:1.1f}%'.format(fname, percentage))\n",
    "            sys.stdout.flush()\n",
    "        fpath, _ = urllib.request.urlretrieve(url, fpath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(fpath)\n",
    "        print('Successfully downloaded', fname, statinfo.st_size, 'bytes.')\n",
    "    return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_path = download_and_cache(TRAIN_URL)\n",
    "    train = pd.read_csv(train_path, header=0, names=['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species'])\n",
    "    train_y = train.pop('Species') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(y_name='Species'):\n",
    "    train_path, test_path = maybe_download()\n",
    "\n",
    "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "\n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      2\n",
       "8      1\n",
       "9      0\n",
       "10     1\n",
       "11     1\n",
       "12     0\n",
       "13     0\n",
       "14     2\n",
       "15     1\n",
       "16     2\n",
       "17     2\n",
       "18     2\n",
       "19     0\n",
       "20     2\n",
       "21     2\n",
       "22     0\n",
       "23     2\n",
       "24     2\n",
       "25     0\n",
       "26     1\n",
       "27     2\n",
       "28     1\n",
       "29     1\n",
       "      ..\n",
       "90     2\n",
       "91     1\n",
       "92     0\n",
       "93     0\n",
       "94     2\n",
       "95     0\n",
       "96     0\n",
       "97     2\n",
       "98     1\n",
       "99     0\n",
       "100    0\n",
       "101    1\n",
       "102    0\n",
       "103    1\n",
       "104    0\n",
       "105    0\n",
       "106    0\n",
       "107    0\n",
       "108    1\n",
       "109    0\n",
       "110    2\n",
       "111    1\n",
       "112    0\n",
       "113    2\n",
       "114    0\n",
       "115    1\n",
       "116    1\n",
       "117    0\n",
       "118    0\n",
       "119    1\n",
       "Name: Species, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "def _parse_line(line):\n",
    "    fields = tf.decode_csv(line, record_defaults=CSV_TYPES)\n",
    "\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "\n",
    "    label = features.pop('Species')\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def csv_input_fn(csv_path, batch_size):\n",
    "    dataset = tf.data.TextLineDataset(csv_path).skip(1)\n",
    "\n",
    "    dataset = dataset.map(_parse_line)\n",
    "\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
