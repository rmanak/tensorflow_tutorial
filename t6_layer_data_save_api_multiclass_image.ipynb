{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.6\n",
    "with gzip.open('datasets/mnist.pkl.gz', 'rb') as fp:\n",
    "    train_set, valid_set, test_set = pickle.load(fp, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_set\n",
    "valid_X, valid_y = valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_id = 50\n",
    "plt.imshow(train_X[element_id].reshape(28, 28), cmap='Greys')\n",
    "plt.title(\"This is `{}`\".format(train_y[element_id]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API: https://www.tensorflow.org/api_docs/python/tf/layers/dense\n",
    "# Class API: https://www.tensorflow.org/api_docs/python/tf/layers/Dense\n",
    "def neural_net(input_layer, hidden_layers=[1024, 256, 64], num_classes=10, \n",
    "               with_dropout=True,\n",
    "               with_batch_norm=False,\n",
    "               activation=tf.nn.relu):\n",
    "        \n",
    "    layer = input_layer\n",
    "    \n",
    "    if with_batch_norm:\n",
    "        layer = tf.layers.batch_normalization(layer)\n",
    "\n",
    "\n",
    "    for l, units in enumerate(hidden_layers):\n",
    "        layer = tf.layers.dense(layer, units=units, activation=activation)\n",
    "        if with_dropout:\n",
    "            layer = tf.layers.dropout(layer, rate=0.8)\n",
    "\n",
    "    logits = tf.layers.dense(layer, units=num_classes)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('input_placeholder'):\n",
    "    X_placeholder = tf.placeholder(shape=(None, 784), dtype=tf.float32, name='inputX')\n",
    "    Y_placeholder = tf.placeholder(shape=(None), dtype=tf.int64, name='inputY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_EPOCH = 25\n",
    "learning_rate = 0.0004\n",
    "\n",
    "batch_size = tf.placeholder(dtype=tf.int64)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_placeholder, Y_placeholder))\n",
    "dataset = dataset.batch(batch_size)\n",
    "data_iterator = dataset.make_initializable_iterator()\n",
    "input_layer, labels = data_iterator.get_next()\n",
    "\n",
    "logits = neural_net(input_layer)\n",
    "loss_op = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "pred_classes_op = tf.argmax(logits, axis=1)\n",
    "# acc_op = tf.metrics.accuracy(labels, pred_classes_op)\n",
    "\n",
    "correct_pred = tf.equal(pred_classes_op, labels)\n",
    "acc_op = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "def report_train_valid_accuracy(epoch, sess):\n",
    "    sess.run(data_iterator.initializer, feed_dict={X_placeholder: train_X, \n",
    "                                                   Y_placeholder: train_y,\n",
    "                                                   batch_size: train_X.shape[0]})\n",
    "    loss, acc = sess.run([loss_op, acc_op])\n",
    "    print(f\"epoch={epoch} loss={loss:0.5f} acc={acc:0.5f} \", end='')\n",
    "    \n",
    "\n",
    "        \n",
    "    sess.run(data_iterator.initializer, feed_dict={X_placeholder: valid_X, \n",
    "                                                       Y_placeholder: valid_y,\n",
    "                                                       batch_size: valid_X.shape[0]})\n",
    "        \n",
    "    loss, acc = sess.run([loss_op, acc_op]) \n",
    "    print(f\"test_loss={loss:0.5f} test_acc={acc:0.5f}\")\n",
    "    \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # For tf.metrics.accuracy\n",
    "    # sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    report_train_valid_accuracy(0, sess)\n",
    "    \n",
    "    \n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        sess.run(data_iterator.initializer, feed_dict={X_placeholder: train_X, \n",
    "                                                       Y_placeholder: train_y,\n",
    "                                                       batch_size: BATCH_SIZE})\n",
    "        while True:\n",
    "            try:\n",
    "                loss, _= sess.run([loss_op, train_op])\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                        \n",
    "        report_train_valid_accuracy(epoch+1, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
