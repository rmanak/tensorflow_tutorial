{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import urllib.request\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEMP_DIR = '/tmp/tensorflow_tutorials'\n",
    "\n",
    "def download_and_cache(url, fname=None, dest=TEMP_DIR):\n",
    "    if not os.path.exists(dest):\n",
    "        os.makedirs(dest)\n",
    "    if fname is None:\n",
    "        fname = url.split('/')[-1]\n",
    "        print(\"Using fname:\", fname)\n",
    "    fpath = os.path.join(dest, fname)\n",
    "    if not os.path.exists(fpath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            percentage = float(count * block_size) / float(total_size) * 100.0\n",
    "            sys.stdout.write('\\r>> Downloading {} {:1.1f}%'.format(fname, percentage))\n",
    "            sys.stdout.flush()\n",
    "        fpath, _ = urllib.request.urlretrieve(url, fpath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(fpath)\n",
    "        print('Successfully downloaded', fname, statinfo.st_size, 'bytes.')\n",
    "    return fpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "\n",
    "FEAT_COLUMNS = ['SepalLength', 'SepalWidth',\n",
    "                'PetalLength', 'PetalWidth']\n",
    "\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def _parse_line(line):\n",
    "    fields = tf.decode_csv(line, record_defaults=CSV_TYPES)\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "    label = features.pop('Species')\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def csv_input_fn(csv_path, batch_size, shuffle_repeat=True):\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(csv_path).skip(1)\n",
    "    dataset = dataset.map(_parse_line)\n",
    "    \n",
    "    # no need to repeat and shuffle during eval or pred mode\n",
    "    if shuffle_repeat:\n",
    "        dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    else:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def input_fn(url, shuffle_repeat=True, batch_size=100):\n",
    "    path = download_and_cache(url) \n",
    "    return csv_input_fn(path, batch_size=batch_size, \n",
    "                        shuffle_repeat=shuffle_repeat)\n",
    "\n",
    "def infer_input_fn(features, batch_size=100):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_net(features, feature_column, \n",
    "               hidden_units, output_units):\n",
    "    \n",
    "    layer = tf.feature_column.input_layer(features, feature_column)\n",
    "    for units in hidden_units:\n",
    "        layer = tf.layers.dense(layer, units=units, activation=tf.nn.relu)\n",
    "    \n",
    "    logits = tf.layers.dense(layer, units=output_units, activation=None)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_function(features, labels, mode, params):\n",
    "    feature_columns = params['feature_columns']\n",
    "    hidden_units = params['hidden_units']\n",
    "    output_units = params['output_layer_class_num']\n",
    "    \n",
    "    logits = neural_net(features, feature_columns, hidden_units, output_units)\n",
    "    \n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probs = tf.nn.softmax(logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {'logits': logits,\n",
    "                       'probs': pred_probs,\n",
    "                       'class': pred_classes}\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=pred_classes,\n",
    "                                   name='accuracy_op')\n",
    "    \n",
    "    \n",
    "    # See https://stackoverflow.com/questions/46409626/how-to-properly-use-tf-metrics-accuracy\n",
    "    # As to why accuracy returns 2 values. \n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        metrics = {'accuracy': accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key=key) for key in FEAT_COLUMNS]\n",
    "\n",
    "model = tf.estimator.Estimator(model_function,\n",
    "                               params={\n",
    "                                   'feature_columns': feature_columns,\n",
    "                                   'hidden_units': [10, 10],\n",
    "                                   'output_layer_class_num': 3\n",
    "                               },\n",
    "                               model_dir=TEMP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.train(input_fn=lambda: input_fn(TRAIN_URL), steps=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can run tensorboard and see the progress:\n",
    "# !tensorboard --logdir=/tmp/tensorflow_tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_results = model.evaluate(input_fn=lambda: input_fn(TEST_URL, shuffle_repeat=False))\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "X = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "    }\n",
    "\n",
    "infer_results = model.predict(input_fn=lambda: infer_input_fn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(infer_results, expected):\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class']\n",
    "    prob = pred_dict['probs'][class_id]\n",
    "\n",
    "    print(template.format(SPECIES[class_id],\n",
    "                            100 * prob, expec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
